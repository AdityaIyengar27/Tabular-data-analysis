{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "#### 1. Is it possible to predict the product tier from the information given in the other columns?\n",
    "#### 2. Is it possible to predict detail views from the information given in the other columns?\n",
    "\n",
    "#### To start with, import few of libraries which are going to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function reads a csv file and returns a pandas dataframe.\n",
    "Delimeter can be passed as a parameter\n",
    "\n",
    "Input : filename - Name of the csv file with extension\n",
    "        delimeter - delimeter of the file (default: \",\")\n",
    "\n",
    "Returns: A pandas dataframe\n",
    "\"\"\"\n",
    "\n",
    "def readcsv_for_pandas(filename, delimiter=\",\"):\n",
    "    data = pd.read_csv(filename, delimiter=delimiter)\n",
    "#     print(data_train.head())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = readcsv_for_pandas(\"/Users/adityaiyengar/Desktop/AS24_Case_Study_Data.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **For the first task, lets concentrate on the column \\'product_tier\\'**\n",
    "* **Let's plot differnt values of this column to get an idea of the data set** <br><br>\n",
    " PS - Please run this cell twice, as on the first run the plot doesn't come up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_product_tier = pd.value_counts(data['product_tier']).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As seen from the above plot, there are more than 75,000 \"Basic\" values and comparatively very few for \"Premium\" and \"Plus\". <br>\n",
    "This makes the dataset imbalanced for the first task. <br>**\n",
    "**Hence, let's try to use Random forest initially for building a model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, we have to preprocess the data. <br>\n",
    "To begin with, we can remove NANs(if any) from the data. <br>\n",
    "Also, we can look at the datatype of the columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article_id : <class 'str'>\n",
      "product_tier : <class 'str'>\n",
      "make_name : <class 'str'>\n",
      "price : <class 'str'>\n",
      "first_zip_digit : <class 'str'>\n",
      "first_registration_year : <class 'str'>\n",
      "created_date : <class 'str'>\n",
      "deleted_date : <class 'str'>\n",
      "search_views : <class 'str'>\n",
      "detail_views : <class 'str'>\n",
      "stock_days : <class 'str'>\n",
      "ctr : <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This function removes NAN (not a number) from a pandas dataframe.\n",
    "\n",
    "Input : dataframe - Pandas dataframe\n",
    "\n",
    "Returns: A pandas dataframe\n",
    "\"\"\"\n",
    "\n",
    "def removeNAN(dataframe):\n",
    "    for columnName in data:\n",
    "        data[data[columnName].notna()]\n",
    "        print(columnName + \" : \" + str(type(columnName)))\n",
    "    return data\n",
    "data = removeNAN(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   article_id product_tier      make_name  price  first_zip_digit  \\\n",
      "0   350625839        Basic     Mitsubishi  16750                5   \n",
      "1   354412280        Basic  Mercedes-Benz  35950                4   \n",
      "2   349572992        Basic  Mercedes-Benz  11950                3   \n",
      "3   350266763        Basic           Ford   1750                6   \n",
      "4   355688985        Basic  Mercedes-Benz  26500                3   \n",
      "\n",
      "   first_registration_year created_date deleted_date  search_views  \\\n",
      "0                     2013     24.07.18     24.08.18        3091.0   \n",
      "1                     2015     16.08.18     07.10.18        3283.0   \n",
      "2                     1998     16.07.18     05.09.18        3247.0   \n",
      "3                     2003     20.07.18     29.10.18        1856.0   \n",
      "4                     2014     28.08.18     08.09.18         490.0   \n",
      "\n",
      "   detail_views  stock_days                   ctr  \n",
      "0         123.0          30   0.03780329990294403  \n",
      "1         223.0          52   0.06792567773378008  \n",
      "2         265.0          51    0.0816137973514013  \n",
      "3          26.0         101  0.014008620689655173  \n",
      "4          20.0          12   0.04081632653061224  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **As seen from above, all column are string values.**\n",
    "* **Let us convert the different 'make_name' string values to interger values as this becomes essential for training the model. (One hot encoding can also be used, but I do it this way)**\n",
    "* **'product_tier' is used as a label column for training the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make name unique labels:  [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91]\n"
     ]
    }
   ],
   "source": [
    "article_id = data.article_id\n",
    "\n",
    "# data['product_tier'] = pd.factorize(data['product_tier'] )[0] + 1\n",
    "# print(\"Product tier unique labels: \", np.unique(data['product_tier']))\n",
    "\n",
    "product_tier = data.product_tier\n",
    "\n",
    "data['make_name'] = pd.factorize(data['make_name'] )[0] + 1\n",
    "print(\"make name unique labels: \", np.unique(data['make_name']))    # To know the unique labels for 'make_name'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Let me drop the columns article_id, first_zip_digit, created_date, deleted_date as I don't see these features contribute to the classification task. <br>**\n",
    "* **Also, let us convert the columns - first_registration_year, search_views, detail_views, stock_days, ctr to floating values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make_name</th>\n",
       "      <th>price</th>\n",
       "      <th>first_registration_year</th>\n",
       "      <th>search_views</th>\n",
       "      <th>detail_views</th>\n",
       "      <th>stock_days</th>\n",
       "      <th>ctr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16750</td>\n",
       "      <td>2013</td>\n",
       "      <td>3091.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.03780329990294403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>35950</td>\n",
       "      <td>2015</td>\n",
       "      <td>3283.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.06792567773378008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11950</td>\n",
       "      <td>1998</td>\n",
       "      <td>3247.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>51</td>\n",
       "      <td>0.0816137973514013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1750</td>\n",
       "      <td>2003</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>101</td>\n",
       "      <td>0.014008620689655173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>26500</td>\n",
       "      <td>2014</td>\n",
       "      <td>490.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.04081632653061224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   make_name  price  first_registration_year  search_views  detail_views  \\\n",
       "0          1  16750                     2013        3091.0         123.0   \n",
       "1          2  35950                     2015        3283.0         223.0   \n",
       "2          2  11950                     1998        3247.0         265.0   \n",
       "3          3   1750                     2003        1856.0          26.0   \n",
       "4          2  26500                     2014         490.0          20.0   \n",
       "\n",
       "   stock_days                   ctr  \n",
       "0          30   0.03780329990294403  \n",
       "1          52   0.06792567773378008  \n",
       "2          51    0.0816137973514013  \n",
       "3         101  0.014008620689655173  \n",
       "4          12   0.04081632653061224  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = data.drop(['article_id', 'product_tier', 'first_zip_digit', 'created_date', 'deleted_date'], axis=1)\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Now I can *convert search_views, detail_views and ctr* to float values and remove NANs, if any that come up after conversion.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['search_views'] = pd.to_numeric(new_data.search_views, downcast=\"float\", errors='coerce')\n",
    "new_data = new_data[new_data['search_views'].notna()]\n",
    "\n",
    "new_data['detail_views'] = pd.to_numeric(new_data.detail_views, downcast=\"float\", errors='coerce')\n",
    "new_data = new_data[new_data['detail_views'].notna()]\n",
    "\n",
    "new_data['ctr'] = pd.to_numeric(new_data.ctr, downcast=\"float\", errors='coerce')\n",
    "new_data =  new_data[new_data['ctr'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [78215, 78321]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-d52662b4ade6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduct_tier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2170\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2172\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2174\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \"\"\"\n\u001b[1;32m    298\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 263\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [78215, 78321]"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(new_data, product_tier,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **The above error tells us that there are few rows dropped from training_data which were not dropped from 'product_tier' as we removed that column before converting.**\n",
    "* **Hence, we repeat the entire process but keeping 'product_tier' column and dropping it later.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_tier</th>\n",
       "      <th>make_name</th>\n",
       "      <th>price</th>\n",
       "      <th>first_registration_year</th>\n",
       "      <th>search_views</th>\n",
       "      <th>detail_views</th>\n",
       "      <th>stock_days</th>\n",
       "      <th>ctr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic</td>\n",
       "      <td>1</td>\n",
       "      <td>16750</td>\n",
       "      <td>2013</td>\n",
       "      <td>3091.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.03780329990294403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Basic</td>\n",
       "      <td>2</td>\n",
       "      <td>35950</td>\n",
       "      <td>2015</td>\n",
       "      <td>3283.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.06792567773378008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Basic</td>\n",
       "      <td>2</td>\n",
       "      <td>11950</td>\n",
       "      <td>1998</td>\n",
       "      <td>3247.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>51</td>\n",
       "      <td>0.0816137973514013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basic</td>\n",
       "      <td>3</td>\n",
       "      <td>1750</td>\n",
       "      <td>2003</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>101</td>\n",
       "      <td>0.014008620689655173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Basic</td>\n",
       "      <td>2</td>\n",
       "      <td>26500</td>\n",
       "      <td>2014</td>\n",
       "      <td>490.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.04081632653061224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_tier  make_name  price  first_registration_year  search_views  \\\n",
       "0        Basic          1  16750                     2013        3091.0   \n",
       "1        Basic          2  35950                     2015        3283.0   \n",
       "2        Basic          2  11950                     1998        3247.0   \n",
       "3        Basic          3   1750                     2003        1856.0   \n",
       "4        Basic          2  26500                     2014         490.0   \n",
       "\n",
       "   detail_views  stock_days                   ctr  \n",
       "0         123.0          30   0.03780329990294403  \n",
       "1         223.0          52   0.06792567773378008  \n",
       "2         265.0          51    0.0816137973514013  \n",
       "3          26.0         101  0.014008620689655173  \n",
       "4          20.0          12   0.04081632653061224  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = data.drop(['article_id', 'first_zip_digit', 'created_date', 'deleted_date'], axis=1)\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data['search_views'] = pd.to_numeric(training_data.search_views, downcast=\"float\", errors='coerce')\n",
    "training_data = training_data[training_data['search_views'].notna()]\n",
    "\n",
    "training_data['detail_views'] = pd.to_numeric(training_data.detail_views, downcast=\"float\", errors='coerce')\n",
    "training_data = training_data[training_data['detail_views'].notna()]\n",
    "\n",
    "training_data['ctr'] = pd.to_numeric(training_data.ctr, downcast=\"float\", errors='coerce')\n",
    "training_data =  training_data[training_data['ctr'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **We drop column - product_tier and split the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_tier = training_data.product_tier\n",
    "training_data = training_data.drop(['product_tier'], axis=1)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(training_data, product_tier,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62572, 7)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make_name</th>\n",
       "      <th>price</th>\n",
       "      <th>first_registration_year</th>\n",
       "      <th>search_views</th>\n",
       "      <th>detail_views</th>\n",
       "      <th>stock_days</th>\n",
       "      <th>ctr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66885</th>\n",
       "      <td>6</td>\n",
       "      <td>24750</td>\n",
       "      <td>2018</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58830</th>\n",
       "      <td>17</td>\n",
       "      <td>9950</td>\n",
       "      <td>2010</td>\n",
       "      <td>2894.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.050449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33140</th>\n",
       "      <td>5</td>\n",
       "      <td>1950</td>\n",
       "      <td>2003</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.009488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52058</th>\n",
       "      <td>6</td>\n",
       "      <td>17900</td>\n",
       "      <td>2017</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12620</th>\n",
       "      <td>8</td>\n",
       "      <td>2995</td>\n",
       "      <td>2007</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.057971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       make_name  price  first_registration_year  search_views  detail_views  \\\n",
       "66885          6  24750                     2018         212.0           0.0   \n",
       "58830         17   9950                     2010        2894.0         146.0   \n",
       "33140          5   1950                     2003        1054.0          10.0   \n",
       "52058          6  17900                     2017          40.0           0.0   \n",
       "12620          8   2995                     2007          69.0           4.0   \n",
       "\n",
       "       stock_days       ctr  \n",
       "66885          22  0.000000  \n",
       "58830          36  0.050449  \n",
       "33140          19  0.009488  \n",
       "52058           7  0.000000  \n",
       "12620          -1  0.057971  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Till now, we have been processing or preprocessing the data. Next, we train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use random forest method to train the model and later, we use the test data to test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **I use random search for hyper-parameter tuning (through a dictionary)**\n",
    "* **I use a dictionary to set the parameter distribution. The best value of n_estimators and max_depth can be estimated later on (in between the range of the defined values)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_grid = {'n_estimators':np.arange(20,100,10),\n",
    "              'max_depth':np.arange(10,60,10),\n",
    "              'class_weight':['balanced']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Train a random classifier using the above dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestClassifier(), n_iter=20,\n",
       "                   param_distributions={'class_weight': ['balanced'],\n",
       "                                        'max_depth': array([10, 20, 30, 40, 50]),\n",
       "                                        'n_estimators': array([20, 30, 40, 50, 60, 70, 80, 90])},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier()\n",
    "randomforest_classifier = RandomizedSearchCV(estimator=rf_classifier, param_distributions = random_grid, n_iter =20, random_state=42)\n",
    "randomforest_classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Find the best values for n_estimators and max_depth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 90, 'max_depth': 20, 'class_weight': 'balanced'}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomforest_classifier.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Select the best model for prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = randomforest_classifier.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function prints values and returns predicted values from a model.\n",
    "\n",
    "Input : x_test - test values\n",
    "        y_test - test labels\n",
    "        model - ML model\n",
    "\n",
    "Returns: prediction - predicted values from the model\n",
    "\"\"\"\n",
    "\n",
    "def print_test_pred_values(x_test, y_test, model):\n",
    "    prediction = model.predict(x_test)\n",
    "    print()\n",
    "    print(\"Unique test values for product tier: \", np.unique(y_test))\n",
    "    print()\n",
    "    print(\"Unique prediction values for product tier: \", np.unique(prediction))\n",
    "    print()\n",
    "    print(\"First 10 test values: \")\n",
    "    print(y_test[:10])\n",
    "    print()\n",
    "    print(\"First 10 predicted values: \", prediction[:10])\n",
    "    acc = metrics.accuracy_score(prediction, y_test)\n",
    "    print()\n",
    "    print(\"Accuracy: \", acc)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique test values for product tier:  ['Basic' 'Plus' 'Premium']\n",
      "\n",
      "Unique prediction values for product tier:  ['Basic' 'Premium']\n",
      "\n",
      "First 10 test values: \n",
      "40081    Basic\n",
      "70879    Basic\n",
      "6066     Basic\n",
      "44178    Basic\n",
      "63897    Basic\n",
      "9379     Basic\n",
      "16755    Basic\n",
      "44858    Basic\n",
      "56469    Basic\n",
      "15317    Basic\n",
      "Name: product_tier, dtype: object\n",
      "\n",
      "First 10 predicted values:  ['Basic' 'Basic' 'Basic' 'Basic' 'Basic' 'Basic' 'Basic' 'Basic' 'Basic'\n",
      " 'Basic']\n",
      "\n",
      "Accuracy:  0.9711692130665474\n"
     ]
    }
   ],
   "source": [
    "prediction = print_test_pred_values(x_test, y_test, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function prints number of values for each class.\n",
    "\n",
    "Input : y_test - test labels\n",
    "        prediction - predicted values from the model\n",
    "\n",
    "Returns: None\n",
    "\"\"\"\n",
    "\n",
    "def print_test_pred_data(y_test, prediction):\n",
    "    count1_test = count2_test = count3_test = 0\n",
    "    for j in y_test:\n",
    "        if j=='Basic' or j==1:\n",
    "            count1_test+=1\n",
    "        if j=='Plus' or j==2:\n",
    "            count2_test+=1\n",
    "        if j=='Premium' or j==3:\n",
    "            count3_test+=1\n",
    "    print()\n",
    "    print(\"Labels for test data\")\n",
    "    print(\"Basic: \", count1_test, \", Plus: \", count2_test, \", Premium: \", count3_test)\n",
    "    print()\n",
    "\n",
    "    count1_pred = count2_pred = count3_pred = 0\n",
    "    for j in prediction:\n",
    "        if j=='Basic' or j==1:\n",
    "            count1_pred+=1\n",
    "        if j=='Plus' or j==2:\n",
    "            count2_pred+=1\n",
    "        if j=='Premium' or j==3:\n",
    "            count3_pred+=1\n",
    "    print(\"Labels for prediction data\")\n",
    "    print(\"Basic: \", count1_pred, \", Plus: \", count2_pred, \", Premium: \", count3_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labels for test data\n",
      "Basic:  15050 , Plus:  116 , Premium:  477\n",
      "\n",
      "Labels for prediction data\n",
      "Basic:  15350 , Plus:  0 , Premium:  293\n"
     ]
    }
   ],
   "source": [
    "print_test_pred_data(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **As you can see, the accuracy for the model is high. But that is because the model is able to predict the class-'Basic', but not the other two classes. This is because of imbalance in the data (with huge number of samples for class-'Basic'). This is despite using 'class_weight' parameter during training.**\n",
    "* **I get the same result if I use a simple random forest without random search.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique test values for product tier:  ['Basic' 'Plus' 'Premium']\n",
      "\n",
      "Unique prediction values for product tier:  ['Basic' 'Plus' 'Premium']\n",
      "\n",
      "First 10 test values: \n",
      "40081    Basic\n",
      "70879    Basic\n",
      "6066     Basic\n",
      "44178    Basic\n",
      "63897    Basic\n",
      "9379     Basic\n",
      "16755    Basic\n",
      "44858    Basic\n",
      "56469    Basic\n",
      "15317    Basic\n",
      "Name: product_tier, dtype: object\n",
      "\n",
      "First 10 predicted values:  ['Basic' 'Basic' 'Basic' 'Basic' 'Basic' 'Basic' 'Basic' 'Basic' 'Basic'\n",
      " 'Basic']\n",
      "\n",
      "Accuracy:  0.9698906859298089\n",
      "\n",
      "Labels for test data\n",
      "Basic:  15050 , Plus:  116 , Premium:  477\n",
      "\n",
      "Labels for prediction data\n",
      "Basic:  15415 , Plus:  2 , Premium:  226\n"
     ]
    }
   ],
   "source": [
    "random_forest_model = RandomForestClassifier(n_estimators=20, class_weight=\"balanced\")\n",
    "random_forest_model.fit(x_train,y_train)\n",
    "prediction = print_test_pred_values(x_test, y_test, random_forest_model)\n",
    "print_test_pred_data(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Instead, we try using Balanced random forest classifier of imblearn and verify the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique test values for product tier:  ['Basic' 'Plus' 'Premium']\n",
      "\n",
      "Unique prediction values for product tier:  ['Basic' 'Plus' 'Premium']\n",
      "\n",
      "First 10 test values: \n",
      "40081    Basic\n",
      "70879    Basic\n",
      "6066     Basic\n",
      "44178    Basic\n",
      "63897    Basic\n",
      "9379     Basic\n",
      "16755    Basic\n",
      "44858    Basic\n",
      "56469    Basic\n",
      "15317    Basic\n",
      "Name: product_tier, dtype: object\n",
      "\n",
      "First 10 predicted values:  ['Basic' 'Basic' 'Basic' 'Basic' 'Basic' 'Basic' 'Basic' 'Basic' 'Basic'\n",
      " 'Basic']\n",
      "\n",
      "Accuracy:  0.7789426580579173\n",
      "\n",
      "Labels for test data\n",
      "Basic:  15050 , Plus:  116 , Premium:  477\n",
      "\n",
      "Labels for prediction data\n",
      "Basic:  11883 , Plus:  2884 , Premium:  876\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "balanced_random_forest_model = BalancedRandomForestClassifier(n_estimators=20)\n",
    "balanced_random_forest_model.fit(x_train,y_train)\n",
    "\n",
    "prediction = print_test_pred_values(x_test, y_test, balanced_random_forest_model)\n",
    "print_test_pred_data(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **As seen, the balanced random forest classifier produces results with less accuracy**\n",
    "* **The next option which I looked into was upsampling the data. The problem with this approach is the training time increases. We can use sklearn's resample utility function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Basic      75421\n",
       "Premium     2324\n",
       "Plus         576\n",
       "Name: product_tier, dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.product_tier.value_counts()   # Displays the number of samples for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = data[data.product_tier==\"Basic\"]\n",
    "df_minority_1 = data[data.product_tier==\"Plus\"]\n",
    "df_minority_2 = data[data.product_tier==\"Premium\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Now, we try to upsample to balance the different classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample minority class\n",
    "\n",
    "df_minority_upsampled_1 = resample(df_minority_1, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=data.product_tier.value_counts()[0],    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "df_minority_upsampled_2 = resample(df_minority_2, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=data.product_tier.value_counts()[0],    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Premium    75421\n",
       "Plus       75421\n",
       "Basic      75421\n",
       "Name: product_tier, dtype: int64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled_1, df_minority_upsampled_2])\n",
    " \n",
    "# Display new class counts\n",
    "df_upsampled.product_tier.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Now, we repeat the same process as in the above examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   article_id product_tier  make_name  price  first_zip_digit  \\\n",
      "0   350625839        Basic          1  16750                5   \n",
      "1   354412280        Basic          2  35950                4   \n",
      "2   349572992        Basic          2  11950                3   \n",
      "3   350266763        Basic          3   1750                6   \n",
      "4   355688985        Basic          2  26500                3   \n",
      "\n",
      "   first_registration_year created_date deleted_date  search_views  \\\n",
      "0                     2013     24.07.18     24.08.18        3091.0   \n",
      "1                     2015     16.08.18     07.10.18        3283.0   \n",
      "2                     1998     16.07.18     05.09.18        3247.0   \n",
      "3                     2003     20.07.18     29.10.18        1856.0   \n",
      "4                     2014     28.08.18     08.09.18         490.0   \n",
      "\n",
      "   detail_views  stock_days                   ctr  \n",
      "0         123.0          30   0.03780329990294403  \n",
      "1         223.0          52   0.06792567773378008  \n",
      "2         265.0          51    0.0816137973514013  \n",
      "3          26.0         101  0.014008620689655173  \n",
      "4          20.0          12   0.04081632653061224  \n",
      "\n",
      "make name unique labels:  [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      " 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_product_tier = pd.value_counts(df_upsampled['product_tier']).plot.bar()\n",
    "\n",
    "print()\n",
    "print(df_upsampled.head())\n",
    "\n",
    "product_tier = df_upsampled.product_tier\n",
    "\n",
    "df_upsampled['make_name'] = pd.factorize(df_upsampled['make_name'] )[0] + 1\n",
    "print()\n",
    "print(\"make name unique labels: \", np.unique(df_upsampled['make_name']))    # To know the unique labels for 'make_name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_up_sampled = df_upsampled.drop(['article_id', 'first_zip_digit', 'created_date', 'deleted_date'], axis=1)\n",
    "\n",
    "training_data_up_sampled['search_views'] = pd.to_numeric(training_data_up_sampled.search_views, downcast=\"float\", errors='coerce')\n",
    "training_data_up_sampled = training_data_up_sampled[training_data_up_sampled['search_views'].notna()]\n",
    "\n",
    "training_data_up_sampled['detail_views'] = pd.to_numeric(training_data_up_sampled.detail_views, downcast=\"float\", errors='coerce')\n",
    "training_data_up_sampled = training_data_up_sampled[training_data_up_sampled['detail_views'].notna()]\n",
    "\n",
    "training_data_up_sampled['ctr'] = pd.to_numeric(training_data_up_sampled.ctr, downcast=\"float\", errors='coerce')\n",
    "training_data_up_sampled =  training_data_up_sampled[training_data_up_sampled['ctr'].notna()]\n",
    "\n",
    "product_tier = training_data_up_sampled.product_tier\n",
    "training_data_up_sampled = training_data_up_sampled.drop(['product_tier'], axis=1)\n",
    "\n",
    "x_train_up_sampled,x_test_up_sampled,y_train_up_sampled,y_test_up_sampled=train_test_split(training_data_up_sampled, product_tier,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(180668, 7)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make_name</th>\n",
       "      <th>price</th>\n",
       "      <th>first_registration_year</th>\n",
       "      <th>search_views</th>\n",
       "      <th>detail_views</th>\n",
       "      <th>stock_days</th>\n",
       "      <th>ctr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48030</th>\n",
       "      <td>12</td>\n",
       "      <td>31900</td>\n",
       "      <td>2016</td>\n",
       "      <td>27438.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>90</td>\n",
       "      <td>0.015417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23287</th>\n",
       "      <td>10</td>\n",
       "      <td>5745</td>\n",
       "      <td>2010</td>\n",
       "      <td>1482.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.040486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>17</td>\n",
       "      <td>39900</td>\n",
       "      <td>2018</td>\n",
       "      <td>4640.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.020690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53229</th>\n",
       "      <td>7</td>\n",
       "      <td>3250</td>\n",
       "      <td>1999</td>\n",
       "      <td>18119.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.034163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31397</th>\n",
       "      <td>31</td>\n",
       "      <td>14900</td>\n",
       "      <td>2008</td>\n",
       "      <td>1664.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.025841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       make_name  price  first_registration_year  search_views  detail_views  \\\n",
       "48030         12  31900                     2016       27438.0         423.0   \n",
       "23287         10   5745                     2010        1482.0          60.0   \n",
       "435           17  39900                     2018        4640.0          96.0   \n",
       "53229          7   3250                     1999       18119.0         619.0   \n",
       "31397         31  14900                     2008        1664.0          43.0   \n",
       "\n",
       "       stock_days       ctr  \n",
       "48030          90  0.015417  \n",
       "23287           3  0.040486  \n",
       "435            14  0.020690  \n",
       "53229          35  0.034163  \n",
       "31397          13  0.025841  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print()\n",
    "print(x_train_up_sampled.shape)\n",
    "print()\n",
    "x_train_up_sampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique test values for product tier:  ['Basic' 'Plus' 'Premium']\n",
      "\n",
      "Unique prediction values for product tier:  ['Basic' 'Plus' 'Premium']\n",
      "\n",
      "First 10 test values: \n",
      "53477       Plus\n",
      "59117       Plus\n",
      "52797       Plus\n",
      "24171       Plus\n",
      "28042       Plus\n",
      "48954    Premium\n",
      "70808       Plus\n",
      "26035    Premium\n",
      "6864     Premium\n",
      "46084       Plus\n",
      "Name: product_tier, dtype: object\n",
      "\n",
      "First 10 predicted values:  ['Plus' 'Plus' 'Plus' 'Plus' 'Plus' 'Premium' 'Plus' 'Premium' 'Premium'\n",
      " 'Plus']\n",
      "\n",
      "Accuracy:  0.9968561813673397\n",
      "\n",
      "Labels for test data\n",
      "Basic:  15089 , Plus:  15029 , Premium:  15050\n",
      "\n",
      "Labels for prediction data\n",
      "Basic:  14947 , Plus:  15041 , Premium:  15180\n"
     ]
    }
   ],
   "source": [
    "random_forest_model_upsampled = RandomForestClassifier(n_estimators=20, class_weight=\"balanced\")\n",
    "random_forest_model_upsampled.fit(x_train_up_sampled,y_train_up_sampled)\n",
    "prediction_up_sampled = print_test_pred_values(x_test_up_sampled, y_test_up_sampled, random_forest_model_upsampled)\n",
    "print_test_pred_data(y_test_up_sampled, prediction_up_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **As you can see upsampling drastically improves the results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **For the second task, we will build a random forest regression model, as we are trying to predict a number.**\n",
    "* **We follow the same steps as in the previous tasks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product tier unique labels:  [1 2 3]\n",
      "\n",
      "   product_tier  make_name  price  first_registration_year  search_views  \\\n",
      "0             1          1  16750                     2013        3091.0   \n",
      "1             1          2  35950                     2015        3283.0   \n",
      "2             1          2  11950                     1998        3247.0   \n",
      "3             1          3   1750                     2003        1856.0   \n",
      "4             1          2  26500                     2014         490.0   \n",
      "\n",
      "   detail_views  stock_days       ctr  \n",
      "0         123.0          30  0.037803  \n",
      "1         223.0          52  0.067926  \n",
      "2         265.0          51  0.081614  \n",
      "3          26.0         101  0.014009  \n",
      "4          20.0          12  0.040816  \n"
     ]
    }
   ],
   "source": [
    "training_data_regressor = df_upsampled.drop(['article_id', 'first_zip_digit', 'created_date', 'deleted_date'], axis=1)\n",
    "\n",
    "training_data_regressor['product_tier'] = pd.factorize(training_data_regressor['product_tier'] )[0] + 1\n",
    "print(\"Product tier unique labels: \", np.unique(training_data_regressor['product_tier']))\n",
    "\n",
    "training_data_regressor['search_views'] = pd.to_numeric(training_data_regressor.search_views, downcast=\"float\", errors='coerce')\n",
    "training_data_regressor = training_data_regressor[training_data_regressor['search_views'].notna()]\n",
    "\n",
    "training_data_regressor['detail_views'] = pd.to_numeric(training_data_regressor.detail_views, downcast=\"float\", errors='coerce')\n",
    "training_data_regressor = training_data_regressor[training_data_regressor['detail_views'].notna()]\n",
    "\n",
    "training_data_regressor['ctr'] = pd.to_numeric(training_data_regressor.ctr, downcast=\"float\", errors='coerce')\n",
    "training_data_regressor = training_data_regressor[training_data_regressor['ctr'].notna()]\n",
    "\n",
    "print()\n",
    "print(training_data_regressor.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **We drop column - detail_views and split the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_views = training_data_regressor.detail_views\n",
    "training_data_regressor = training_data_regressor.drop(['detail_views'], axis=1)\n",
    "\n",
    "x_train_regressor,x_test_regressor,y_train_regressor,y_test_regressor=train_test_split(training_data_regressor, detail_views, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(180668, 7)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_tier</th>\n",
       "      <th>make_name</th>\n",
       "      <th>price</th>\n",
       "      <th>first_registration_year</th>\n",
       "      <th>search_views</th>\n",
       "      <th>stock_days</th>\n",
       "      <th>ctr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12984</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4950</td>\n",
       "      <td>2004</td>\n",
       "      <td>11487.0</td>\n",
       "      <td>49</td>\n",
       "      <td>0.063637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32769</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1450</td>\n",
       "      <td>1999</td>\n",
       "      <td>13830.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.022632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53257</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13400</td>\n",
       "      <td>2017</td>\n",
       "      <td>465.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.064516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27824</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>47995</td>\n",
       "      <td>2018</td>\n",
       "      <td>1198.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.050083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30689</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>16750</td>\n",
       "      <td>2013</td>\n",
       "      <td>4754.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.026083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_tier  make_name  price  first_registration_year  search_views  \\\n",
       "12984             2         12   4950                     2004       11487.0   \n",
       "32769             3          4   1450                     1999       13830.0   \n",
       "53257             1          3  13400                     2017         465.0   \n",
       "27824             2         17  47995                     2018        1198.0   \n",
       "30689             3         10  16750                     2013        4754.0   \n",
       "\n",
       "       stock_days       ctr  \n",
       "12984          49  0.063637  \n",
       "32769          12  0.022632  \n",
       "53257           2  0.064516  \n",
       "27824          15  0.050083  \n",
       "30689          42  0.026083  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print()\n",
    "print(x_train_regressor.shape)\n",
    "print()\n",
    "x_train_regressor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function prints various evaluation measures for regression model.\n",
    "\n",
    "Input : x_test - test values\n",
    "        y_test - test labels\n",
    "        prediction - regression model\n",
    "\n",
    "Returns: None\n",
    "\"\"\"\n",
    "\n",
    "def evaluate_regression_model(x_test, y_test, model):\n",
    "    prediction = model.predict(x_test)\n",
    "    print()\n",
    "    print(\"First 10 test values: \")\n",
    "    print(y_test[:10])\n",
    "    print()\n",
    "    print(\"First 10 predicted values: \", prediction[:10])\n",
    "    print()\n",
    "    print(\"Mean absolute error =\", round(metrics.mean_absolute_error(y_test, prediction), 2))\n",
    "    print()\n",
    "    print(\"Mean squared error =\", round(metrics.mean_squared_error(y_test, prediction), 2)) \n",
    "    print()\n",
    "    print(\"Median absolute error =\", round(metrics.median_absolute_error(y_test, prediction), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_regressor_model = RandomForestRegressor()\n",
    "rf_regressor_model.fit(x_train_regressor,y_train_regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 test values: \n",
      "626        5.0\n",
      "17185     20.0\n",
      "38304    977.0\n",
      "47962     95.0\n",
      "70932     44.0\n",
      "10797      1.0\n",
      "13821    306.0\n",
      "60334    372.0\n",
      "76555    269.0\n",
      "59331    501.0\n",
      "Name: detail_views, dtype: float32\n",
      "\n",
      "First 10 predicted values:  [  5.    19.99 977.    95.53  44.     1.   306.   372.   269.   501.  ]\n",
      "\n",
      "Mean absolute error = 0.86\n",
      "\n",
      "Mean squared error = 401.76\n",
      "\n",
      "Median absolute error = 0.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate_regression_model(x_test_regressor, y_test_regressor, rf_regressor_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **There seems to be small amount of prediction error for few values, but not many, from this model.**\n",
    "* **This regression model is for the upsampled data.**\n",
    "\n",
    "PS: I can build this model for the original data as well as it is on the similar lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **I will also try to build a multi layer perceptron model for the upsampled data set, for the classification task.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(x_train, y_train_onehot):\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    # add input layer\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=50,\n",
    "        input_dim=x_train.shape[1]\n",
    "        )\n",
    "    )\n",
    "    # add hidden layer\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(\n",
    "            units=16,\n",
    "            input_dim=32,\n",
    "            activation='relu')\n",
    "        )\n",
    "    # add output layer\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(\n",
    "            units=y_train_onehot.shape[1],\n",
    "            input_dim=16,\n",
    "            activation='softmax')\n",
    "        )\n",
    "\n",
    "    # compile model\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product tier unique labels:  [1 2 3]\n",
      "\n",
      "   product_tier  make_name  price  first_registration_year  search_views  \\\n",
      "0             1          1  16750                     2013        3091.0   \n",
      "1             1          2  35950                     2015        3283.0   \n",
      "2             1          2  11950                     1998        3247.0   \n",
      "3             1          3   1750                     2003        1856.0   \n",
      "4             1          2  26500                     2014         490.0   \n",
      "\n",
      "   detail_views  stock_days       ctr  \n",
      "0         123.0          30  0.037803  \n",
      "1         223.0          52  0.067926  \n",
      "2         265.0          51  0.081614  \n",
      "3          26.0         101  0.014009  \n",
      "4          20.0          12  0.040816  \n"
     ]
    }
   ],
   "source": [
    "training_data_mlp = df_upsampled.drop(['article_id', 'first_zip_digit', 'created_date', 'deleted_date'], axis=1)\n",
    "\n",
    "training_data_mlp['product_tier'] = pd.factorize(training_data_mlp['product_tier'] )[0] + 1\n",
    "print(\"Product tier unique labels: \", np.unique(training_data_mlp['product_tier']))\n",
    "\n",
    "training_data_mlp['search_views'] = pd.to_numeric(training_data_mlp.search_views, downcast=\"float\", errors='coerce')\n",
    "training_data_mlp = training_data_mlp[training_data_mlp['search_views'].notna()]\n",
    "\n",
    "training_data_mlp['detail_views'] = pd.to_numeric(training_data_mlp.detail_views, downcast=\"float\", errors='coerce')\n",
    "training_data_mlp = training_data_mlp[training_data_mlp['detail_views'].notna()]\n",
    "\n",
    "training_data_mlp['ctr'] = pd.to_numeric(training_data_mlp.ctr, downcast=\"float\", errors='coerce')\n",
    "training_data_mlp = training_data_mlp[training_data_mlp['ctr'].notna()]\n",
    "\n",
    "print()\n",
    "print(training_data_mlp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_tier_mlp = training_data_mlp.product_tier\n",
    "training_data_mlp = training_data_mlp.drop(['product_tier'], axis=1)\n",
    "\n",
    "x_train_mlp,x_test_mlp,y_train_mlp,y_test_mlp=train_test_split(training_data_mlp, product_tier_mlp,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 250.4277 - accuracy: 0.4912 - val_loss: 29.9703 - val_accuracy: 0.4493\n",
      "Epoch 2/50\n",
      "2823/2823 [==============================] - 3s 1ms/step - loss: 24.1260 - accuracy: 0.5375 - val_loss: 11.3682 - val_accuracy: 0.6206\n",
      "Epoch 3/50\n",
      "2823/2823 [==============================] - 3s 1ms/step - loss: 17.2905 - accuracy: 0.5478 - val_loss: 14.7797 - val_accuracy: 0.4834\n",
      "Epoch 4/50\n",
      "2823/2823 [==============================] - 3s 1ms/step - loss: 15.1233 - accuracy: 0.5463 - val_loss: 11.8485 - val_accuracy: 0.6146\n",
      "Epoch 5/50\n",
      "2823/2823 [==============================] - 3s 1ms/step - loss: 11.6185 - accuracy: 0.5485 - val_loss: 24.9559 - val_accuracy: 0.5053\n",
      "Epoch 6/50\n",
      "2823/2823 [==============================] - 3s 1ms/step - loss: 10.0515 - accuracy: 0.5416 - val_loss: 4.7669 - val_accuracy: 0.6200\n",
      "Epoch 7/50\n",
      "2823/2823 [==============================] - 3s 1ms/step - loss: 5.7585 - accuracy: 0.5504 - val_loss: 4.7501 - val_accuracy: 0.5261\n",
      "Epoch 8/50\n",
      "2823/2823 [==============================] - 3s 1ms/step - loss: 3.0631 - accuracy: 0.5510 - val_loss: 0.8420 - val_accuracy: 0.6275\n",
      "Epoch 9/50\n",
      "2823/2823 [==============================] - 3s 1ms/step - loss: 0.8453 - accuracy: 0.6146 - val_loss: 0.8278 - val_accuracy: 0.6189\n",
      "Epoch 10/50\n",
      "2823/2823 [==============================] - 3s 1ms/step - loss: 0.8695 - accuracy: 0.6023 - val_loss: 0.8451 - val_accuracy: 0.6161\n",
      "Epoch 11/50\n",
      "2823/2823 [==============================] - 3s 1ms/step - loss: 0.8411 - accuracy: 0.6239 - val_loss: 0.8403 - val_accuracy: 0.6012\n",
      "Epoch 12/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8910 - accuracy: 0.6109 - val_loss: 0.8092 - val_accuracy: 0.6203\n",
      "Epoch 13/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8318 - accuracy: 0.6256 - val_loss: 0.8416 - val_accuracy: 0.5888\n",
      "Epoch 14/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8375 - accuracy: 0.6228 - val_loss: 0.8339 - val_accuracy: 0.6057\n",
      "Epoch 15/50\n",
      "2823/2823 [==============================] - 3s 1ms/step - loss: 0.8361 - accuracy: 0.6248 - val_loss: 0.8506 - val_accuracy: 0.6009\n",
      "Epoch 16/50\n",
      "2823/2823 [==============================] - 3s 1ms/step - loss: 0.8385 - accuracy: 0.6230 - val_loss: 0.8224 - val_accuracy: 0.6373\n",
      "Epoch 17/50\n",
      "2823/2823 [==============================] - 3s 1ms/step - loss: 0.8401 - accuracy: 0.6190 - val_loss: 0.8451 - val_accuracy: 0.6264\n",
      "Epoch 18/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8368 - accuracy: 0.6229 - val_loss: 0.8203 - val_accuracy: 0.6270\n",
      "Epoch 19/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8349 - accuracy: 0.6239 - val_loss: 0.8679 - val_accuracy: 0.6204\n",
      "Epoch 20/50\n",
      "2823/2823 [==============================] - 3s 1ms/step - loss: 0.8340 - accuracy: 0.6252 - val_loss: 0.8069 - val_accuracy: 0.6382\n",
      "Epoch 21/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8308 - accuracy: 0.6287 - val_loss: 0.8063 - val_accuracy: 0.6291\n",
      "Epoch 22/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8291 - accuracy: 0.6273 - val_loss: 0.8134 - val_accuracy: 0.6282\n",
      "Epoch 23/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8285 - accuracy: 0.6302 - val_loss: 0.8012 - val_accuracy: 0.6551\n",
      "Epoch 24/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8253 - accuracy: 0.6302 - val_loss: 0.8189 - val_accuracy: 0.6159\n",
      "Epoch 25/50\n",
      "2823/2823 [==============================] - 3s 1ms/step - loss: 0.8269 - accuracy: 0.6306 - val_loss: 0.8175 - val_accuracy: 0.6447\n",
      "Epoch 26/50\n",
      "2823/2823 [==============================] - 3s 1ms/step - loss: 0.8197 - accuracy: 0.6345 - val_loss: 0.8501 - val_accuracy: 0.6410\n",
      "Epoch 27/50\n",
      "2823/2823 [==============================] - 3s 1ms/step - loss: 0.8237 - accuracy: 0.6313 - val_loss: 0.8046 - val_accuracy: 0.6484\n",
      "Epoch 28/50\n",
      "2823/2823 [==============================] - 3s 1ms/step - loss: 0.8243 - accuracy: 0.6322 - val_loss: 0.8227 - val_accuracy: 0.6295\n",
      "Epoch 29/50\n",
      "2823/2823 [==============================] - 3s 1ms/step - loss: 0.8214 - accuracy: 0.6315 - val_loss: 0.7881 - val_accuracy: 0.6528\n",
      "Epoch 30/50\n",
      "2823/2823 [==============================] - 3s 1ms/step - loss: 0.8131 - accuracy: 0.6379 - val_loss: 0.8111 - val_accuracy: 0.6354\n",
      "Epoch 31/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8177 - accuracy: 0.6368 - val_loss: 0.7904 - val_accuracy: 0.6482\n",
      "Epoch 32/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8139 - accuracy: 0.6370 - val_loss: 0.7917 - val_accuracy: 0.6364\n",
      "Epoch 33/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8090 - accuracy: 0.6411 - val_loss: 0.8092 - val_accuracy: 0.6385\n",
      "Epoch 34/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8083 - accuracy: 0.6387 - val_loss: 0.7933 - val_accuracy: 0.6518\n",
      "Epoch 35/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8194 - accuracy: 0.6345 - val_loss: 0.8001 - val_accuracy: 0.6463\n",
      "Epoch 36/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8099 - accuracy: 0.6380 - val_loss: 0.7875 - val_accuracy: 0.6419\n",
      "Epoch 37/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8072 - accuracy: 0.6406 - val_loss: 0.8081 - val_accuracy: 0.6464\n",
      "Epoch 38/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8061 - accuracy: 0.6406 - val_loss: 0.8111 - val_accuracy: 0.6330\n",
      "Epoch 39/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8116 - accuracy: 0.6376 - val_loss: 0.7950 - val_accuracy: 0.6300\n",
      "Epoch 40/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8073 - accuracy: 0.6410 - val_loss: 0.8063 - val_accuracy: 0.6301\n",
      "Epoch 41/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8083 - accuracy: 0.6391 - val_loss: 0.7838 - val_accuracy: 0.6528\n",
      "Epoch 42/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8066 - accuracy: 0.6425 - val_loss: 0.8042 - val_accuracy: 0.6307\n",
      "Epoch 43/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8087 - accuracy: 0.6402 - val_loss: 0.7975 - val_accuracy: 0.6433\n",
      "Epoch 44/50\n",
      "2823/2823 [==============================] - 3s 1ms/step - loss: 0.8032 - accuracy: 0.6409 - val_loss: 0.7860 - val_accuracy: 0.6545\n",
      "Epoch 45/50\n",
      "2823/2823 [==============================] - 3s 1ms/step - loss: 0.8056 - accuracy: 0.6401 - val_loss: 0.8162 - val_accuracy: 0.6283\n",
      "Epoch 46/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8049 - accuracy: 0.6425 - val_loss: 0.8043 - val_accuracy: 0.6353\n",
      "Epoch 47/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8014 - accuracy: 0.6451 - val_loss: 0.7924 - val_accuracy: 0.6539\n",
      "Epoch 48/50\n",
      "2823/2823 [==============================] - 4s 1ms/step - loss: 0.8051 - accuracy: 0.6422 - val_loss: 0.7947 - val_accuracy: 0.6350\n",
      "Epoch 49/50\n",
      "2823/2823 [==============================] - 5s 2ms/step - loss: 0.8024 - accuracy: 0.6409 - val_loss: 0.7912 - val_accuracy: 0.6512\n",
      "Epoch 50/50\n",
      "2823/2823 [==============================] - 5s 2ms/step - loss: 0.7993 - accuracy: 0.6468 - val_loss: 0.8177 - val_accuracy: 0.6515\n"
     ]
    }
   ],
   "source": [
    "y_train_onehot = tf.keras.utils.to_categorical(y_train_mlp)\n",
    "y_test_onehot = tf.keras.utils.to_categorical(y_test_mlp)\n",
    "\n",
    "model = get_model(x_train_mlp, y_train_onehot)\n",
    "\n",
    "history = model.fit(\n",
    "    x_train_mlp, y_train_onehot,\n",
    "    batch_size=64, epochs=50,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test_mlp, y_test_onehot)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **I have tried to implement a simple MLP model. This gives a validation accuracy of 65%.**\n",
    "* **I believe I can improve this model further. But, as I have to send this file by today, I won't make further changes. I am deeply sorry for the unfinished MLP model, but I hope you understand.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
